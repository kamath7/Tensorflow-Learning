{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation of Weights Options\n",
    "Xavier Initialisation\n",
    "\n",
    "a) Draw weights from a distribution with zero mean and a specific variance\n",
    "\n",
    "Xavier Initialisation - Check formula \n",
    "\n",
    "Learning Rate - Defines step size during gradient descent\n",
    "Batch Size - Batches allow us to use stochastic gradient descent\n",
    "Smaller- less representative of data\n",
    "Larger - Longer training time\n",
    "\n",
    "### Seconder Order Behavior\n",
    "\n",
    "Allows to adjust learning rate based off the rate of descent\n",
    "a) AdaGrad b) RMSProp c) Adam\n",
    "\n",
    "Adam\n",
    "Allows us to start with larger steps and then eventually go to smaller step sizes\n",
    "Adam allows this change to happen automatically\n",
    "\n",
    "\n",
    "### Unstable/Vanishing Gradient\n",
    "\n",
    "As number of layers increase, the layer towards input will be affected less by error calculation occcuring at output as you go backwards through the network\n",
    "\n",
    "Initialistion and Normalisation will help mitigate these issues\n",
    "\n",
    "\n",
    "### Overfitting and Underfitting a model\n",
    "\n",
    " Overfitting - Works perfect on Training set and test data is not performed well\n",
    " \n",
    " Possibility of overfitting too high. \n",
    " to mitigate\n",
    " a) L1/L2 regularisation - Add penalty for larger weights in the model and not unique to neural networks\n",
    " b) Dropout - Unique to Neural netowrks, remove nuerons during training randomly, Network doesn't over rely on any particular neuron\n",
    " c) Expanding data - Artifically expand data by adding noise, Tilt images, adding low white noise to sound data etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset Notes\n",
    "\n",
    "Single digit image can be represented as an array\n",
    "Can also show in a 2D array (28*28 pixels)\n",
    "Values represent grayscale image\n",
    "arrays can then be flattened to a 1-D vector of 784 numbers.\n",
    "\n",
    "Flattening out image ends up removing some of 2D information such as relationship of a pixel to its neighboring pixels\n",
    "\n",
    "Entire group of 55k images as a tensor (n-dimensional array)\n",
    "For labels - use One Hot encoding. Instead of labels such as one, two -> single array\n",
    "\n",
    "Label represented based off index position in label array. Corresponding label will be a 1 at the index location and zero every where else\n",
    "For ex 4 - [0,0,0,0,1,0....]\n",
    "Labels for training data ends up being a large 2D array\n",
    "\n",
    "\n",
    "#### Basic Approach for MNIST\n",
    "\n",
    "Softmax Regression Approach\n",
    "\n",
    "Softmax regression returns list of values between 0 and 1 that add up to one. Can use this as list of probabilities\n",
    "Softmax as activation function (Learn Formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
