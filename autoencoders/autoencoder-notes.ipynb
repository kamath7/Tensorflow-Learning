{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders\n",
    "\n",
    "Simple neural network and is similar to multi layer perceptron \n",
    "\n",
    "Key difference between autoencoder and typical MLP network is that number of inp neurons is equal to number of op neurons\n",
    "\n",
    "Feed foward network trained to reproduce input at output layer\n",
    "output size is same as input layer\n",
    "\n",
    "2 main parts -> Encoder and decoder\n",
    "Hidden layer takes input and passes out the information\n",
    "\n",
    "Tight weights\n",
    "\n",
    "Hidden layers maintains all information of input\n",
    "Can use hidden layer to extract meaningful features (Similarities to PCA?)\n",
    "\n",
    "## Linear Auto encoder\n",
    "\n",
    "Dimensionality reductions allows to get lower dimension represntation of data\n",
    "Encode creates new features from input features\n",
    "\n",
    "Perform linear transformations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
