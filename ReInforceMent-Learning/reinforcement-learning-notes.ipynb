{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "\n",
    "Allows machines and software agents to automatically determine ideal behavior within specific context in order to maximise performance\n",
    "\n",
    "Many different types of algos that fall under reinforcement learning. Not all come under TF\n",
    "\n",
    "Four main things\n",
    "a) Agent b) Environment c) Action d) Reward\n",
    "\n",
    "Agent - Program or bot, can receive inputs based off environment, performs actions\n",
    "Environment - Actual setting agent is interacting with, often game in examples. Need to represent environment in a way agent can understand\n",
    "\n",
    "Action - Actual interaction agent will perform on environment, moving in environ, choosing next move etc\n",
    "Reward - Metric that allow agent to understand whether or not previous actions helped in achieving the goal\n",
    "\n",
    "OpenAI - Discovering and enacting path to safe artificial general intelligence\n",
    "\n",
    "### Policy Gradients\n",
    "\n",
    "a) Not considering history of actions.\n",
    "\n",
    "Assignement of credit problem \n",
    "We solve the problem by applying a discount rate\n",
    "\n",
    "\n",
    "a) Choose discount rate typically around 0.95-0.99\n",
    "b) Apply a score to action with a formula\n",
    "\n",
    "R is reward, D is discount rate\n",
    "\n",
    "Close discount rate is to 1 , more weight future rewards have. Closer to 0 future rewards dont count\n",
    "Choosing discount rate often depends on specific environ and whether actions have short or long term effects\n",
    "\n",
    "Delayed effect sometimes good actions may receive bad scores due to bad actions that follow, unrelated to their initial action. \n",
    "\n",
    "We can normalize the action scores by subtracting mean and dividing by standard deviation. Significantly increase time in complex environs. \n",
    "\n",
    "multiply gradient vector by action's score\n",
    "Negative scores will create opposite gradients when multiplied\n",
    "Calculate mean of resulting gradient vector for gradient descent\n",
    "\n",
    "\n",
    "#### Learning - Material - https://towardsdatascience.com/policy-gradients-in-a-nutshell-8b72f9743c5d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
